{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word embeddings\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open ('glove.6B.100d.txt','r', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word]=coefs\n",
    "\n",
    "f.close()\n",
    "print ('Found %s word embeddings'%(len(embeddings_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "for line in open('./data/poetry/robert_frost.txt'):\n",
    "    line = line.rstrip()\n",
    "    input_line = '<sos> '+line\n",
    "    target_line = line+' <eos>'\n",
    "    input_texts.append(input_line)\n",
    "    target_texts.append(target_line)\n",
    "    \n",
    "all_lines = input_texts + target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS=20000\n",
    "BATCH_SIZE=122\n",
    "EPOCHS=500\n",
    "OOV_TOKEN=0\n",
    "EMBEDDING_DIM = 100\n",
    "MAX_SEQ_LENGTH=100\n",
    "VALIDATION_SPLIT_RATIO= 0.2\n",
    "LSTM_UNITS=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3057 unique words\n",
      "1374\n",
      "Found 1581 input sequences\n",
      "Found 1581 output sequences\n",
      "max seq length is 12\n",
      "Created 1581 padded input sequences\n",
      "Created 1581 padded target sequences\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS, oov_token=OOV_TOKEN, filters='')\n",
    "tokenizer.fit_on_texts(all_lines)\n",
    "word2Idx = tokenizer.word_index\n",
    "\n",
    "print ('Found %d unique words'%(len(word2Idx)))\n",
    "print (word2Idx['girl'])\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "print ('Found %d input sequences'%(len(input_sequences)))\n",
    "print ('Found %d output sequences'%(len(target_sequences)))\n",
    "\n",
    "max_seq_len_from_data = min (MAX_SEQ_LENGTH, max(len(s) for s in input_sequences))\n",
    "print ('max seq length is %d'%(max_seq_len_from_data))\n",
    "\n",
    "padded_input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, padding='post', maxlen=max_seq_len_from_data)\n",
    "padded_target_sequences = tf.keras.preprocessing.sequence.pad_sequences(target_sequences, padding='post', maxlen=max_seq_len_from_data)\n",
    "\n",
    "print ('Created %d padded input sequences'%(len(padded_input_sequences)))\n",
    "print ('Created %d padded target sequences'%(len(padded_target_sequences)))\n",
    "\n",
    "assert ('<sos>' in word2Idx)\n",
    "assert ('<eos>' in word2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min words to be considered are 3058\n",
      "(3058, 100)\n"
     ]
    }
   ],
   "source": [
    "num_words = min (MAX_WORDS, len(word2Idx)+1)\n",
    "print ('Min words to be considered are %d'%(num_words))\n",
    "\n",
    "loaded_embeddings_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word2Idx.items():\n",
    "    if (i<num_words):\n",
    "        if word in embeddings_index.keys():\n",
    "            embedding_vector = embeddings_index[word]\n",
    "            loaded_embeddings_matrix[i] = embedding_vector\n",
    "\n",
    "print (loaded_embeddings_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105 538 539  10   8 540 541   3   0   0   0   0]\n",
      "[  6 542   7  66  32 935 142   3   0   0   0   0]\n",
      "[  6  28  25 936 153   7 222   3   0   0   0   0]\n",
      "[  6 168  68  25  18 129  18   7  66   3   0   0]\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(padded_target_sequences):\n",
    "    print (seq)\n",
    "    if (i>2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Step:\n",
    "\n",
    "If we look at this problem statement, we have a set of input sequences and corresponding target sequences.\n",
    "\n",
    "Input Seq (T*D)-> Target Seq (T'*D')\n",
    "\n",
    "    T -> number of input sequences\n",
    "    D -> length of each input sequence\n",
    "\n",
    "    T' -> number of target sequences\n",
    "    D' -> length of each target sequence.\n",
    "\n",
    "In a seq2seq scenario the target value needs to be one-hot encoded and that's what we are doing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1581, 12, 3058)\n"
     ]
    }
   ],
   "source": [
    "one_hot_targets = np.zeros((len(target_sequences), max_seq_len_from_data, num_words))\n",
    "print (one_hot_targets.shape)\n",
    "for i, seq in enumerate(padded_target_sequences):\n",
    "    for j, word in enumerate(seq):\n",
    "        if (word>0):\n",
    "            one_hot_targets[i,j,word]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer = tf.keras.layers.Embedding(input_dim = num_words,\n",
    "                               output_dim = EMBEDDING_DIM,\n",
    "                               input_length=max_seq_len_from_data, \n",
    "                               embeddings_initializer=tf.keras.initializers.Constant(loaded_embeddings_matrix),\n",
    "                               trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0914 00:37:55.884897 13104 deprecation.py:506] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 12, 100)      305800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 12, 500), (N 1202000     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 12, 3058)     1532058     lstm[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 3,039,858\n",
      "Trainable params: 3,039,858\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = tf.keras.layers.Input(shape=(max_seq_len_from_data))\n",
    "initial_h = tf.keras.layers.Input(shape=(LSTM_UNITS,))\n",
    "initial_c = tf.keras.layers.Input(shape=(LSTM_UNITS,))\n",
    "\n",
    "x = embed_layer(input_)\n",
    "\n",
    "lstm_layer_0 = tf.keras.layers.LSTM(units=LSTM_UNITS, return_sequences=True, return_state=True)\n",
    "x,_,_ = lstm_layer_0(x)\n",
    "\n",
    "#stm_layer_1 = tf.keras.layers.LSTM(units=LSTM_UNITS, return_sequences=True, return_state=True)\n",
    "#x,_,_ = lstm_layer_1(x)\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(num_words, activation='softmax')\n",
    "output = dense_layer(x)\n",
    "\n",
    "model = tf.keras.models.Model([input_, initial_h, initial_c], output)\n",
    "\n",
    "model.compile (optimizer=tf.keras.optimizers.Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 00:37:56.228919 13104 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1264 samples, validate on 317 samples\n",
      "1264/1264 [==============================] - 9s 7ms/sample - loss: 4.7269 - acc: 0.0708 - val_loss: 4.8074 - val_acc: 0.0904\n"
     ]
    }
   ],
   "source": [
    "h = np.zeros((len(padded_input_sequences),LSTM_UNITS))\n",
    "c = np.zeros((len(padded_input_sequences),LSTM_UNITS))\n",
    "history = model.fit ([padded_input_sequences,h,c], one_hot_targets, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT_RATIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Training Metadata (Accuracy & Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X90XVWd9/H3h/5K6a/0FxaImoAM0IY0DaHgA0pLES0KxdKhzcgARe0CFFz0YbQozwN2ZFZ1HKgoCwSlONppRLqKleHHINQRHh2gwVJoO5gKZYyt0FYB6Q8g8H3+uCfxNr1JQ869ubnt57XWWff82Gff70668u0++5x9FBGYmZn11EHFDsDMzEqbE4mZmaXiRGJmZqk4kZiZWSpOJGZmlooTiZmZpeJEYmZmqTiRmJlZKk4kZmaWSv9iB9AbxowZE5WVlcUOw8yspDQ1NW2LiLH7KndAJJLKykpWr15d7DDMzEqKpBe7U86XtszMLJWiJBJJH5P0nKSNkhbkOD5I0o+T449Lqkz2D5S0RNIzkp6WNKWXQzczsw56PZFI6gfcDEwHxgMNksZ3KPZp4M8R8QHgRuDryf7PAkTEccBHgH+R5F6VmVkRFWOMZDKwMSKeB5DUCMwA1meVmQFcl6zfDXxHksgknocBIuJlSa8A9cATvRO6mRXTW2+9RUtLC7t37y52KPuVsrIyKioqGDBgQI/OL0YiORz4fdZ2C3BiZ2UiolXSq8Bo4GlgRpJ83gscn3w6kZgdAFpaWhg2bBiVlZVk/m9paUUE27dvp6Wlhaqqqh7VUYzLQrl++x3frtVZmTvIJJ7VwGLgV0Brzi+R5klaLWn11q1bU4RrZn3F7t27GT16tJNIHkli9OjRqXp5xUgkLWR6EW0qgM2dlZHUHxgB/CkiWiPiyoiojYgZQDnQnOtLIuK2iKiPiPqxY/d5G7SZlQgnkfxL+zMtRiJ5EjhKUpWkgcAcYGWHMiuBC5P1WcAjERGSDpY0BEDSR4DWiFiPmZkVTa8nkohoBT4PPAhsAO6KiHWSFko6Oyn2fWC0pI3AfKDtFuFDgKckbQC+BPx970ZvZgey7du3U1tbS21tLePGjePwww9v337zzTe7VcfcuXN57rnnuixz8803s3Tp0nyE3CsU0XF4Yv9TX18ffrLdrPRt2LCBY489tthhAHDdddcxdOhQrrrqqj32RwQRwUEHldaTCbl+tpKaIqJ+X+eWVkvNzPqgjRs3Ul1dzSWXXEJdXR1btmxh3rx51NfXM2HCBBYuXNhe9pRTTmHNmjW0trZSXl7OggULmDhxIh/84Ad5+eWXAbjmmmtYvHhxe/kFCxYwefJkjj76aH71q18BsGPHDs4991wmTpxIQ0MD9fX1rFmzpvcbzwEy15aZ7X+++rN1rN/8Wl7rHH/YcK49a0KPzl2/fj1Llizh1ltvBWDRokWMGjWK1tZWpk6dyqxZsxg/fs9nr1999VVOPfVUFi1axPz587njjjtYsGCvyT6ICJ544glWrlzJwoULeeCBB/j2t7/NuHHjWL58OU8//TR1dXU9ijsf3CMxM8uDI488khNOOKF9e9myZdTV1VFXV8eGDRtYv37v+4IGDx7M9OnTATj++OPZtGlTzrpnzpy5V5nHHnuMOXPmADBx4kQmTOhZAswH90jMrCT1tOdQKEOGDGlfb25u5lvf+hZPPPEE5eXlnH/++Tmf0xg4cGD7er9+/WhtzflYHIMGDdqrTF8a33aPxMwsz1577TWGDRvG8OHD2bJlCw8++GDev+OUU07hrrvuAuCZZ57J2ePpLe6RmJnlWV1dHePHj6e6upojjjiCk08+Oe/fcfnll3PBBRdQU1NDXV0d1dXVjBgxIu/f0x2+/dfMSkZfuv232FpbW2ltbaWsrIzm5mbOOOMMmpub6d+/Z/2DNLf/ukdiZlaCXn/9daZNm0ZraysRwXe/+90eJ5G0nEjMzEpQeXk5TU1NxQ4D8GC7mZml5ERiZmapOJGYmVkqTiRmZpaKE4mZWTdNmTJlr4cLFy9ezGWXXdbpOUOHDgVg8+bNzJo1q9N69/WIwuLFi9m5c2f79plnnskrr7zS3dALyonEzKybGhoaaGxs3GNfY2MjDQ0N+zz3sMMO4+677+7xd3dMJPfddx/l5eU9ri+fnEjMzLpp1qxZ3HvvvbzxxhsAbNq0ic2bN1NbW8u0adOoq6vjuOOO46c//ele527atInq6moAdu3axZw5c6ipqWH27Nns2rWrvdyll17aPv38tddeC8BNN93E5s2bmTp1KlOnTgWgsrKSbdu2AXDDDTdQXV1NdXV1+/TzmzZt4thjj+Wzn/0sEyZM4Iwzztjje/LJz5GYWWm6fwH88Zn81jnuOJi+qNPDo0ePZvLkyTzwwAPMmDGDxsZGZs+ezeDBg1mxYgXDhw9n27ZtnHTSSZx99tmdvgv9lltu4eCDD2bt2rWsXbt2jyngr7/+ekaNGsXbb7/NtGnTWLt2LVdccQU33HADq1atYsyYMXvU1dTUxJIlS3j88ceJCE488UROPfVURo4cSXNzM8uWLeP222/nvPPOY/ny5Zx//vn5+VllSdUjkfR5SSPzFYyZWV+XfXmr7bJWRPDlL3+ZmpoaTj/9dP7whz/w0ksvdVrHL3/5y/Y/6DU1NdTU1LQfu+uuu6irq2PSpEmsW7dun5MxPvbYY3zyk59kyJAhDB06lJkzZ/Loo48CUFVVRW1tLdD1NPVppe2RjAOelPQUcAfwYBwIk3eZWfF10XMopHPOOYf58+fz1FNPsWvXLurq6rjzzjvZunUrTU1NDBgwgMrKypzTxmfL1Vt54YUX+OY3v8mTTz7JyJEjueiii/ZZT1d/ctumn4fMFPSFurSVqkcSEdcARwHfBy4CmiX9k6Qj8xCbmVmfM3ToUKZMmcLFF1/cPsj+6quvcsghhzBgwABWrVrFiy++2GUdH/7wh1m6dCkAzz77LGvXrgUy088PGTKEESNG8NJLL3H//fe3nzNs2DD+8pe/5KzrnnvuYefOnezYsYMVK1bwoQ99KF/N7ZbUYyQREZL+CPwRaAVGAndLeigivpi2fjOzvqahoYGZM2e2X+L61Kc+xVlnnUV9fT21tbUcc8wxXZ5/6aWXMnfuXGpqaqitrWXy5MlA5k2HkyZNYsKECXtNPz9v3jymT5/OoYceyqpVq9r319XVcdFFF7XX8ZnPfIZJkyYV7DJWLqmmkZd0BXAhsA34HnBPRLwl6SCgOSL6RM/E08ib7R88jXzhFHMa+THAzIjYox8XEe9I+kTKus3MrASkfY7kPuBPbRuShkk6ESAiNqSs28zMSkDaRHIL8HrW9o5kn5lZQfjG0PxL+zNNm0iUfbtvRLyDH3I0swIpKytj+/btTiZ5FBFs376dsrKyHteR9o/+88mAe1sv5DLg+ZR1mpnlVFFRQUtLC1u3bi12KPuVsrIyKioqenx+2kRyCXATcA0QwMPAvJR1mpnlNGDAAKqqqoodhnWQKpFExMvAnDzFYmZmJShVIpFUBnwamAC0X2CLiItTxmVmZiUi7WD7D8nMt/VR4D+BCmDvZ/jNzGy/lTaRfCAi/g+wIyJ+AHwcOC59WGZmVirSJpK3ks9XJFUDI4DKlHWamVkJSXvX1m3J+0iuAVYCQ4H/kzoqMzMrGT1OJMnEjK9FxJ+BXwJH5C0qMzMrGT2+tJU8xf75PMZiZmYlKO0YyUOSrpL0Xkmj2pa8RGZmZiUhbSK5GPgcmUtbTcmyzxd/SPqYpOckbZS0IMfxQZJ+nBx/XFJlsn+ApB9IekbSBklXp4zfzMxSSvtk+7ueq0BSP+Bm4CNAC5l3vq+MiOw33H8a+HNEfEDSHODrwGzgb4FBEXGcpIOB9ZKWRcSmNO0wM7OeS/tk+wW59kfEv3Zx2mRgY0Q8n9TRCMwAshPJDOC6ZP1u4DuSRGY+ryGS+gODgTeB19K0wczM0kl7++8JWetlwDTgKaCrRHI48Pus7RbgxM7KRESrpFeB0WSSygxgC3AwcGVE/AkzMyuatJe2Ls/eljSCzLQpXVGuqrpZZjLwNnAYMBJ4VNLP23o3HWKZRzIT8fve9759hGRmZj2VdrC9o53AUfso0wK8N2u7AtjcWZnkMtYIMq/0/TvggYh4K5l5+P8BOV9MHxG3RUR9RNSPHTv2XTfEzMy6J1UikfQzSSuT5V7gOeCn+zjtSeAoSVWSBpKZhn5lhzIrgQuT9VnAI8mbGP8HOE0ZQ4CTgP9O0wYzM0sn7RjJN7PWW4EXI6KlqxOSMY/PAw8C/YA7ImKdpIXA6ohYCXwf+KGkjWR6Im3vPLkZWAI8S+by15KIWJuyDWZmloLSvPtYUhWwJSJ2J9uDgff0tdtx6+vrY/XqfT7eYmZmWSQ1RUTO4YNsacdIfgK8k7X9drLPzMwOEGkTSf+IeLNtI1kfmLJOMzMrIWkTyVZJZ7dtSJoBbEtZp5mZlZC0g+2XAEslfSfZbgFyPu1uZmb7p7QPJP4OOEnSUDID935fu5nZASbtcyT/JKk8Il6PiL9IGinpa/kKzszM+r60YyTTI+KVto3kbYlnpqzTzMxKSNpE0k/SoLaN5DmSQV2UNzOz/UzawfYfAQ9LWpJszwV+kLJOMzMrIWkH278haS1wOpkpSx4A3p+PwMzMrDTkY/bfP5J5uv1cMu8j2ZCHOs3MrET0qEci6W/ITKTYAGwHfkzm9t+peYzNzMxKQE8vbf038ChwVkRsBJB0Zd6iMjOzktHTS1vnkrmktUrS7ZKmkfuthmZmtp/rUSKJiBURMRs4BvgFcCXwHkm3SDojj/GZmVkfl2qwPSJ2RMTSiPgEmVfmrgEW5CUyMzMrCXl7Z3tE/CkivhsRp+WrTjMz6/vylkjMzOzA5ERiZmapOJGYmVkqTiRmZpaKE4mZmaXiRGJmZqk4kZiZWSpOJGZmlooTiZmZpeJEYmZmqTiRmJlZKk4kZmaWihOJmZml4kRiZmapOJGYmVkqTiRmZpaKE4mZmaXiRGJmZqk4kZiZWSpOJGZmlkpREomkj0l6TtJGSQtyHB8k6cfJ8cclVSb7PyVpTdbyjqTa3o7fzMz+qtcTiaR+wM3AdGA80CBpfIdinwb+HBEfAG4Evg4QEUsjojYiaoG/BzZFxJrei97MzDoqRo9kMrAxIp6PiDeBRmBGhzIzgB8k63cD0ySpQ5kGYFlBIzUzs30qRiI5HPh91nZLsi9nmYhoBV4FRncoM5suEomkeZJWS1q9devW1EGbmVlu/YvwnR17FgDxbspIOhHYGRHPdvYlEXEbcFtSfqukF3sQazGNAbYVO4he5jYfGNzm0vH+7hQqRiJpAd6btV0BbO6kTIuk/sAI4E9Zx+fwLi5rRcTYnoVaPJJWR0R9sePoTW7zgcFt3v8U49LWk8BRkqokDSSTFFZ2KLMSuDBZnwU8EhEBIOkg4G/JjK2YmVmR9XqPJCJaJX0eeBDoB9wREeskLQRWR8RK4PvADyVtJNMTmZNVxYeBloh4vrdjNzOzvRXj0hYRcR9wX4d9/zdrfTeZXkeuc38BnFTI+PqI24odQBG4zQcGt3k/o+SKkZmZWY94ihQzM0vFicTMzFJxIikiSaMkPSSpOfkc2Um5C5MyzZIuzHF8paROn6npS9K0WdLBkv5d0n9LWidpUe9G/+70dE655NjVyf7nJH20N+NOI8U8eh+R1CTpmeTztN6OvafS/J6T4++T9Lqkq3or5ryLCC9FWoBvAAuS9QXA13OUGQU8n3yOTNZHZh2fCfwb8Gyx21PoNgMHA1OTMgOBR4HpxW5TJ+3sB/wOOCKJ9WlgfIcylwG3JutzgB8n6+OT8oOAqqSefsVuU4HbPAk4LFmvBv5Q7PYUus1Zx5cDPwGuKnZ7erq4R1Jc2XOK/QA4J0eZjwIPRcSfIuLPwEPAxwAkDQXmA1/rhVjzpcdtjoidEbEKIDLztD1F5oHWvijNnHIzgMaIeCMiXgA2JvX1dT1uc0T8JiLaHkxeB5RJGtQrUaeTau5ASeeQ+Y/Sul6KtyCcSIrrPRGxBSD5PCRHma7mJvtH4F+AnYUMMs/SthkASeXAWcDDBYozrTRzynXn3L4oX/PonQv8JiLeKFCc+dTjNksaAnwJ+GovxFlQRXmO5EAi6efAuByHvtLdKnLsi+Q9LB+IiCs7XnMttkK1Oav+/mSmyLkp+u6DqWnmlOvOuX1RPubRm0DmtRFn5DGuQkrT5q8CN0bE63tPbl5anEgKLCJO7+yYpJckHRoRWyQdCryco1gLMCVruwL4BfBB4HhJm8j8Hg+R9IuImEKRFbDNbW4DmiNicR7CLZQ0c8p159y+KNU8epIqgBXABRHxu8KHmxdp2nwiMEvSN4By4B1JuyPiO4UPO8+KPUhzIC/AP7PnwPM3cpQZBbxAZrB5ZLI+qkOZSkpnsD1Vm8mMBy0HDip2W/bRzv5krn1X8ddB2AkdynyOPQdh70rWJ7DnYPvzlMZge5o2lyflzy12O3qrzR3KXEcJD7YXPYADeSFzbfhhoDn5bPtjWQ98L6vcxWQGXDcCc3PUU0qJpMdtJvO/vQA2AGuS5TPFblMXbT0T+C2Zu3q+kuxbCJydrJeRuVtnI/AEcETWuV9JznuOPnpnWj7bDFwD7Mj6va4BDil2ewr9e86qo6QTiadIMTOzVHzXlpmZpeJEYmZmqTiRmJlZKgfE7b9jxoyJysrKYodhZlZSmpqatkU3XlV+QCSSyspKVq9eXewwzMxKiqQXu1POl7bMzCwVJxIzM0vFicTMzFI5IMZIzGz/8NZbb9HS0sLu3buLHcp+paysjIqKCgYMGNCj851IzKxktLS0MGzYMCorKyn1GXP7iohg+/bttLS0UFVV1aM6fGnLzErG7t27GT16tJNIHkli9OjRqXp5TiRmVlKcRPIv7c+04IlEUj9Jv5F0b45j75O0Kjm+VtKZWceulrRR0nOSPpq1/2PJvo2SFhQ6fjOzNtu3b6e2tpba2lrGjRvH4Ycf3r795ptvdquOuXPn8txzz3VZ5uabb2bp0qX5CLlX9MYYyRfITPs9PMexa8jMzX+LpPHAfUBlsj6HzHsZDgN+LulvknNuBj5C5mUxT0paGRHrC90IM7PRo0ezZs0aAK677jqGDh3KVVddtUeZtqnVDzoo9//TlyxZss/v+dznPpc+2F5U0B5J8sazjwPf66RI8NcEM4K/vllsBtAYEW9ExAtk5vGfnCwbI+L5iHgTaEzKmpkVzcaNG6muruaSSy6hrq6OLVu2MG/ePOrr65kwYQILFy5sL3vKKaewZs0aWltbKS8vZ8GCBUycOJEPfvCDvPxy5oWh11xzDYsXL24vv2DBAiZPnszRRx/Nr371KwB27NjBueeey8SJE2loaKC+vr49yfW2QvdIFgNfBIZ1cvw64D8kXQ4MAdpe0Xo48F9Z5VqSfQC/77D/xHwFa2al46s/W8f6za/ltc7xhw3n2rMm9Ojc9evXs2TJEm699VYAFi1axKhRo2htbWXq1KnMmjWL8ePH73HOq6++yqmnnsqiRYuYP38+d9xxBwsW7H3FPiJ44oknWLlyJQsXLuSBBx7g29/+NuPGjWP58uU8/fTT1NXV9SjufChYj0TSJ4CXI6Kpi2INwJ0RUUHmLWM/lHQQkGvkJ7rYn+v750laLWn11q1b32X0ZmbvzpFHHskJJ5zQvr1s2TLq6uqoq6tjw4YNrF+/9xX4wYMHM336dACOP/54Nm3alLPumTNn7lXmscceY86cOQBMnDiRCRN6lgDzoZA9kpOBs5MB9DJguKQfRcT5WWU+DXwMICJ+LakMGEOmp/HerHIV/PWyV2f79xARtwG3AdTX1/s1kGb7mZ72HAplyJAh7evNzc1861vf4oknnqC8vJzzzz8/5+21AwcObF/v168fra2tOeseNGjQXmX60tttC9YjiYirI6IiIirJDJw/0iGJAPwPMA1A0rFkEs5WYCUwR9IgSVXAUWTedfwkcJSkKkkDk3pXFqoNZmY98dprrzFs2DCGDx/Oli1bePDBB/P+Haeccgp33XUXAM8880zOHk9v6fUn2yUtBFZHxErgfwO3S7qSzCWqiyKTZtdJugtYD7QCn4uIt5PzPw88CPQD7oiIdb3dBjOzrtTV1TF+/Hiqq6s54ogjOPnkk/P+HZdffjkXXHABNTU11NXVUV1dzYgRI/L+Pd2hvtQ9KpT6+vrw+0jMSt+GDRs49thjix1Gn9Da2kpraytlZWU0Nzdzxhln0NzcTP/+Pesf5PrZSmqKiPp9neu5tszMStDrr7/OtGnTaG1tJSL47ne/2+MkkpYTiZlZCSovL6epqaubYnuP59oyM7NUnEjMzCwVJxIzM0vFicTMzFJxIjEz66YpU6bs9XDh4sWLueyyyzo9Z+jQoQBs3ryZWbNmdVrvvh5RWLx4MTt37mzfPvPMM3nllVe6G3pBOZGYmXVTQ0MDjY2Ne+xrbGykoaFhn+cedthh3H333T3+7o6J5L777qO8vLzH9eWTE4mZWTfNmjWLe++9lzfeeAOATZs2sXnzZmpra5k2bRp1dXUcd9xx/PSnP93r3E2bNlFdXQ3Arl27mDNnDjU1NcyePZtdu3a1l7v00kvbp5+/9tprAbjpppvYvHkzU6dOZerUqQBUVlaybds2AG644Qaqq6uprq5un35+06ZNHHvssXz2s59lwoQJnHHGGXt8Tz75ORIzK033L4A/PpPfOscdB9MXdXp49OjRTJ48mQceeIAZM2bQ2NjI7NmzGTx4MCtWrGD48OFs27aNk046ibPPPrvTV9jecsstHHzwwaxdu5a1a9fuMQX89ddfz6hRo3j77beZNm0aa9eu5YorruCGG25g1apVjBkzZo+6mpqaWLJkCY8//jgRwYknnsipp57KyJEjaW5uZtmyZdx+++2cd955LF++nPPP7zjlYXrukZiZvQvZl7faLmtFBF/+8pepqanh9NNP5w9/+AMvvfRSp3X88pe/bP+DXlNTQ01NTfuxu+66i7q6OiZNmsS6dev2ORnjY489xic/+UmGDBnC0KFDmTlzJo8++igAVVVV1NbWAl1PU5+WeyRmVpq66DkU0jnnnMP8+fN56qmn2LVrF3V1ddx5551s3bqVpqYmBgwYQGVlZc5p47Pl6q288MILfPOb3+TJJ59k5MiRXHTRRfusp6v5Etumn4fMFPSFurTlHomZ2bswdOhQpkyZwsUXX9w+yP7qq69yyCGHMGDAAFatWsWLL77YZR0f/vCHWbp0KQDPPvssa9euBTLTzw8ZMoQRI0bw0ksvcf/997efM2zYMP7yl7/krOuee+5h586d7NixgxUrVvChD30oX83tFvdIzMzepYaGBmbOnNl+ietTn/oUZ511FvX19dTW1nLMMcd0ef6ll17K3Llzqampoba2lsmTJwOZNx1OmjSJCRMm7DX9/Lx585g+fTqHHnooq1atat9fV1fHRRdd1F7HZz7zGSZNmlSwy1i5eBp5MysZnka+cNJMI+9LW2ZmlooTiZmZpeJEYmZmqTiRmFlJORDGdXtb2p9pwROJpH6SfiPp3hzHbpS0Jll+K+mVZP/UrP1rJO2WdE5y7E5JL2Qdqy10G8ysbygrK2P79u1OJnkUEWzfvp2ysrIe19Ebt/9+AdgADO94ICKubFuXdDkwKdm/CqhN9o8CNgL/kXXqP0REz2c/M7OSVFFRQUtLC1u3bi12KPuVsrIyKioqenx+QROJpArg48D1wPx9FG8Ars2xfxZwf0TszHHMzA4gAwYMoKqqqthhWAeFvrS1GPgi8E5XhSS9H6gCHslxeA6wrMO+6yWtTS6NDcpxjpmZ9ZJuJRJJR7b9wZY0RdIVkrqcCF/SJ4CXI6KpG18xB7g7It7uUMehwHFA9ptkrgaOAU4ARgFf6uT750laLWm1u8FmZoXT3R7JcuBtSR8Avk+m9/Bv+zjnZOBsSZuARuA0ST/qpGyuXgfAecCKiHirbUdEbImMN4AlwORcFUbEbRFRHxH1Y8eO3UeoZmbWU91NJO9ERCvwSWBxMkh+aFcnRMTVEVEREZVkEsUjEbHXRPiSjgZGAr/OUU0DHRJM0ktBmakzzwGe7WYbzMysALo72P6WpAbgQuCsZN+AnnyhpIXA6ohYmexqABqjw/18kiqB9wL/2aGKpZLGAgLWAJf0JA4zM8uPbk3aKGk8mT/Yv46IZZKqgNkRUZwXArxLnrTRzOzd6+6kjd3qkUTEeuCKpOKRwLBSSSJmZlZY3b1r6xeShicPBz4NLJF0Q2FDMzOzUtDdwfYREfEaMBNYEhHHA6cXLiwzMysV3U0k/ZO7pc4D9pozy8zMDlzdTSQLyTwU+LuIeFLSEUBz4cIyM7NS0d3B9p8AP8nafh44t1BBmZlZ6ejuYHuFpBWSXpb0kqTlyYSMZmZ2gOvupa0lwErgMOBw4GfJPjMzO8B1N5GMjYglEdGaLHcCnsDKzMy6nUi2STo/edthP0nnA9sLGZiZmZWG7iaSi8nc+vtHYAuZl03NLVRQZmZWOrqVSCLifyLi7IgYGxGHRMQ5ZB5ONDOzA1yaNyTu69W5ZmZ2AEiTSJS3KMzMrGSlSST7nn/ezMz2e10+2S7pL+ROGAIGFyQiMzMrKV0mkogY1luBmJlZaUpzacvMzMyJxMzM0il4IkmehP+NpL3eYyLpRklrkuW3kl7JOvZ21rGVWfurJD0uqVnSjyUNLHQbzMysc92aRj6lLwAbgOEdD0TElW3rki4HJmUd3hURtTnq+zpwY0Q0SroV+DRwS35DNjOz7ipojySZav7jwPe6UbwBWLaP+gScBtyd7PoBcE6aGM3MLJ1CX9paDHwReKerQpLeD1QBj2TtLpO0WtJ/SWpLFqOBVyKiNdluITOtfa465yXnr966dWuqRpiZWecKlkgkfQJ4OSKaulF8DnB3RLydte99EVEP/B2wWNKR5H6aPueDkRFxW0TUR0T92LGe8d7MrFAK2SM5GThb0iagEThN0o86KTuHDpe1ImJz8vk88Asy4yfbgHJJbWM7FcDmvEduZmbdVrBEEhFXR0RFRFSSSRSPRMT5HctJOhoYCfyGkGkuAAAIGUlEQVQ6a99ISYOS9TFkktL6iAhgFZlp7AEuBH5aqDaYmdm+9fpzJJIWSjo7a1cD0JgkiTbHAqslPU0mcSyKiPXJsS8B8yVtJDNm8v3eiNvMzHLTnn+/90/19fWxevXqYodhZlZSJDUlY9Vd8pPtZmaWihOJmZml4kRiZmapOJGYmVkqTiRmZpaKE4mZmaXiRGJmZqk4kZiZWSpOJGZmlooTiZmZpeJEYmZmqTiRmJlZKk4kZmaWihOJmZml4kRiZmapOJGYmVkqTiRmZpaKE4mZmaXiRGJmZqkUPJFI6ifpN5LuzXHsRklrkuW3kl5J9tdK+rWkdZLWSpqddc6dkl7IOq+20G0wM7PO9e+F7/gCsAEY3vFARFzZti7pcmBSsrkTuCAimiUdBjRJejAiXkmO/0NE3F3guM3MrBsK2iORVAF8HPheN4o3AMsAIuK3EdGcrG8GXgbGFipOMzPruUJf2loMfBF4p6tCkt4PVAGP5Dg2GRgI/C5r9/XJJa8bJQ3qpM55klZLWr1169YeN8DMzLpWsEQi6RPAyxHR1I3ic4C7I+LtDnUcCvwQmBsRbcnoauAY4ARgFPClXBVGxG0RUR8R9WPHujNjZlYoheyRnAycLWkT0AicJulHnZSdQ3JZq42k4cC/A9dExH+17Y+ILZHxBrAEmFyI4M3MrHsUEYX/EmkKcFVEfCLHsaOBB4GqSIKRNBC4H/hZRCzuUP7QiNgiScCNwO6IWLCP798KvJiXxvSeMcC2YgfRy9zmA4PbXDreHxH7vKTTG3dt7UHSQmB1RKxMdjUAjbFnRjsP+DAwWtJFyb6LImINsFTSWEDAGuCSfX1nd34QfY2k1RFRX+w4epPbfGBwm/c/vdIjsXdvf/+Hl4vbfGBwm/c/frLdzMxScSLpu24rdgBF4DYfGNzm/YwvbZmZWSrukZiZWSpOJEUkaZSkhyQ1J58jOyl3YVKmWdKFOY6vlPRs4SNOL02bJR0s6d8l/Xcyoeei3o3+3ZH0MUnPSdooaa9b1CUNkvTj5Pjjkiqzjl2d7H9O0kd7M+40etpmSR+R1CTpmeTztN6OvafS/J6T4++T9Lqkq3or5ryLCC9FWoBvAAuS9QXA13OUGQU8n3yOTNZHZh2fCfwb8Gyx21PoNgMHA1OTMgOBR4HpxW5TJ+3sR2ZanyOSWJ8Gxncocxlwa7I+B/hxsj4+KT+IzNRBvwP6FbtNBW7zJOCwZL0a+EOx21PoNmcdXw78hMyzdkVvU08W90iKawbwg2T9B8A5Ocp8FHgoIv4UEX8GHgI+BiBpKDAf+FovxJovPW5zROyMiFUAEfEm8BRQ0Qsx98RkYGNEPJ/E2kim7dmyfxZ3A9OSB21nkHm26o2IeAHYSGnM4NDjNkfEbyIzQSvAOqCss3n0+pg0v2cknUPmP0rreinegnAiKa73RMQWyEz9AhySo8zhwO+ztluSfQD/CPwLmWn3S0XaNgMgqRw4C3i4QHGmtc82ZJeJiFbgVWB0N8/ti9K0Odu5wG8iMw1SX9fjNksaQmauwK/2QpwF1etPth9oJP0cGJfj0Fe6W0WOfZG80OsDEXFlx2uuxVaoNmfV35/M3Gw3RcTz7z7CXtFlG/ZRpjvn9kVp2pw5KE0Avg6ckce4CilNm78K3BgRrycdlJLlRFJgEXF6Z8ckvZQ1d9ihZN670lELMCVruwL4BfBB4PhkUsz+wCGSfhERUyiyAra5zW1Ac3SYh62PaQHem7VdAWzupExLkhxHAH/q5rl9UZo2t72/aAWZl9r9jtKQps0nArMkfQMoB96RtDsivlP4sPOs2IM0B/IC/DN7Djx/I0eZUcALZAabRybrozqUqaR0BttTtZnMeNBy4KBit2Uf7exP5tp3FX8dhJ3Qoczn2HMQ9q5kfQJ7DrY/T2kMtqdpc3lS/txit6O32tyhzHWU8GB70QM4kBcy14YfBpqTz7Y/lvXA97LKXUxmwHUjmXezdKynlBJJj9tM5n97QebVzWuS5TPFblMXbT0T+C2Zu3q+kuxbCJydrJeRuVtnI/AEcETWuV9JznuOPnpnWj7bDFwD7Mj6va4BDil2ewr9e86qo6QTiZ9sNzOzVHzXlpmZpeJEYmZmqTiRmJlZKk4kZmaWihOJmZml4kRi1kOS3pa0JmvZa+bXFHVXlsqMzmZ+st2s53ZFRG2xgzArNvdIzPJM0iZJX5f0RLJ8INn/fkkPS1qbfL4v2f8eSSskPZ0s/yupqp+k25N3r/yHpMFJ+SskrU/qaSxSM83aOZGY9dzgDpe2Zmcdey0iJgPfAdrmBPsO8K8RUQMsBW5K9t8E/GdETATq+OuU4kcBN0fEBOAVMrPiQmZqmUlJPZcUqnFm3eUn2816SNLrETE0x/5NwGkR8bykAcAfI2K0pG3AoRHxVrJ/S0SMkbQVqIisadOTGZ0fioijku0vAQMi4muSHgBeB+4B7omI1wvcVLMuuUdiVhjRyXpnZXLJfh/H2/x1TPPjwM3A8UBTMqOsWdE4kZgVxuysz18n678iM/srwKeAx5L1h4FLAST1kzS8s0olHQS8NzJvivwimVlz9+oVmfUm/0/GrOcGS1qTtf1ARLTdAjxI0uNk/rPWkOy7ArhD0j8AW4G5yf4vALdJ+jSZnselwJZOvrMf8CNJI8i8MOnGiHglby0y6wGPkZjlWTJGUh8R24odi1lv8KUtMzNLxT0SMzNLxT0SMzNLxYnEzMxScSIxM7NUnEjMzCwVJxIzM0vFicTMzFL5//k20REHa3wdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "figure = plt.figure()\n",
    "\n",
    "ax1 = figure.add_subplot(211)\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels=['Training','Validation'])\n",
    "\n",
    "ax1 = figure.add_subplot(212)\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels=['Training','Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             305800      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     multiple             1202000     embedding[1][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   multiple             1532058     lstm[1][0]                       \n",
      "==================================================================================================\n",
      "Total params: 3,039,858\n",
      "Trainable params: 3,039,858\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input2_ = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "x = embed_layer(input2_)\n",
    "x,h,c = lstm_layer_0(x, initial_state = [initial_h, initial_c])\n",
    "#x,h,c = lstm_layer_1(x)\n",
    "\n",
    "output2_ = dense_layer(x)\n",
    "\n",
    "pred_model = tf.keras.models.Model([input2_, initial_h, initial_c], [output2_,h,c])\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "['what- ', 'there ', 'outdoors. ', 'attic, ', 'no ', 'it, ', 'ourselves ', 'cellar. ', 'skulls ', \"aren't \", 'of ']\n"
     ]
    }
   ],
   "source": [
    "test_input_word = '<sos>'\n",
    "test_input_word_idx = word2Idx[test_input_word]\n",
    "test_input_word_vector = np.array([[test_input_word_idx]])\n",
    "\n",
    "print (test_input_word_vector.shape)\n",
    "\n",
    "h = np.zeros((1,LSTM_UNITS))\n",
    "c = np.zeros((1,LSTM_UNITS))\n",
    "\n",
    "output_poem = []\n",
    "eos = word2Idx['<eos>']\n",
    "idx2word = {v:k for k, v in word2Idx.items()}\n",
    "\n",
    "for i in range(max_seq_len_from_data):\n",
    "    \n",
    "    o,h,c = pred_model.predict([test_input_word_vector, h, c])\n",
    "    \n",
    "    probs = o[0,0]\n",
    "    if (np.argmax(probs)==0):\n",
    "        print ('hell!')\n",
    "    probs[0] = 0\n",
    "    probs = probs/probs.sum()\n",
    "    \n",
    "    idx = np.random.choice(len(probs), p=probs)\n",
    "    if (idx == eos):\n",
    "        break\n",
    "    \n",
    "    test_input_word_vector[0,0] = idx\n",
    "    \n",
    "    output_poem.append(idx2word.get(idx) + ' ')\n",
    "    \n",
    "print (output_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
