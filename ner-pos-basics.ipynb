{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('C:\\\\MachineLearning\\\\repos\\\\personel\\\\nlp\\\\ner-pos\\\\en_core_web_sm-2.2.5\\\\en_core_web_sm\\\\en_core_web_sm-2.2.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showEnts(document):\n",
    "    if document.ents:\n",
    "        for ent in document.ents:\n",
    "            print (ent.text + '--'+ent.label_+'--'+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print ('no entities found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "# document with no entities\n",
    "document = nlp('hi, how are you?')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "# document with some entities - CAPABILITIES is not an entity\n",
    "document= nlp('capabilities in india')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "# document with some entities - CAPABILITIES & SETTLEMENT are not an entity\n",
    "document= nlp('settlement capabilities in india')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "# document with some entities - CAPABILITIES, SETTLEMENT & FINANCE are not an entity\n",
    "document= nlp('finance and reconcilliation capabilities in india')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Tags\n",
    "Tags are accessible through the `.label_` property of an entity.\n",
    "<table>\n",
    "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "# document with some entities - CAPABILITIES, SETTLEMENT , FINANCE, Names are not an entity\n",
    "document= nlp('what does rahul jain do in Fidelity india?')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settlement--NORP--Nationalities or religious or political groups\n"
     ]
    }
   ],
   "source": [
    "# Add a word as Named Entity\n",
    "from spacy.tokens import Span\n",
    "\n",
    "document= nlp('settlement capabilities in india')\n",
    "\n",
    "NORP = document.vocab.strings['NORP']\n",
    "new_entity = Span(document,0,1,label=NORP)\n",
    "document.ents = list(document.ents) + [new_entity]\n",
    "\n",
    "#document= nlp('settlement capabilities in india')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settlement--NORP--Nationalities or religious or political groups\n",
      "finance--NORP--Nationalities or religious or political groups\n",
      "reconcilliation--NORP--Nationalities or religious or political groups\n",
      "\n",
      "\n",
      "\n",
      "('how', '', '', '')\n",
      "('many', '', '', '')\n",
      "('settlement', '', '', '')\n",
      "(',', '', '', '')\n",
      "('finance', '', '', '')\n",
      "('and', '', '', '')\n",
      "('reconcilliation', '', '', '')\n",
      "('capabilities', '', '', '')\n",
      "('in', '', '', '')\n",
      "('india', '', '', '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MachineLearning\\anaconda3\\envs\\transformers-gpu\\lib\\runpy.py:193: UserWarning: [W005] Doc object not parsed. This means displaCy won't be able to generate a dependency visualization for it. Make sure the Doc was processed with a model that supports dependency parsing, and not just a language class like `English()`. For more info, see the docs:\n",
      "https://spacy.io/usage/models\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a5954c1df11f4576855129ca7233d1c2-0\" class=\"displacy\" width=\"1625\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">how</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">many</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">settlement,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">finance</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">reconcilliation</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">capabilities</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\"></tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">india</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\"></tspan>\n",
       "</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add multiple phrases as entities\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "\n",
    "document= nlp('how many settlement, finance and reconcilliation capabilities in india')\n",
    "#showEnts(document)\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "phrase_list = ['settlement','finance','reconcilliation']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "matcher.add('capabilities-matcher',None, *phrase_patterns)\n",
    "found_matches = matcher(document)\n",
    "\n",
    "from spacy.tokens import Span\n",
    "NORP = document.vocab.strings['NORP']\n",
    "\n",
    "new_entity = [Span(document, match[1], match[2], label=NORP) for match in found_matches]\n",
    "document.ents = list(document.ents)+new_entity\n",
    "    \n",
    "showEnts(document)\n",
    "print ('\\n\\n')\n",
    "for token in document:\n",
    "    print((token.text, token.pos_, token.tag_, token.dep_))\n",
    "displacy.render(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "document= nlp('settlement capabilities')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_trf_distilbertbaseuncased_lg==2.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_trf_distilbertbaseuncased_lg-2.2.0/en_trf_distilbertbaseuncased_lg-2.2.0.tar.gz (245.0 MB)\n",
      "Requirement already satisfied: spacy>=2.2.1 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from en_trf_distilbertbaseuncased_lg==2.2.0) (2.2.3)\n",
      "Collecting spacy-transformers>=0.5.0\n",
      "  Downloading spacy-transformers-0.5.1.tar.gz (59 kB)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.0.1)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (7.3.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.18.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: setuptools in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (45.1.0.post20200127)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (0.6.0)\n",
      "Collecting transformers<2.1.0,>=2.0.0\n",
      "  Downloading transformers-2.0.0-py3-none-any.whl (290 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.4.0)\n",
      "Collecting torchcontrib<0.1.0,>=0.0.2\n",
      "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\n",
      "Collecting ftfy<6.0.0,>=5.0.0\n",
      "  Downloading ftfy-5.6.tar.gz (58 kB)\n",
      "Collecting dataclasses<0.7,>=0.6\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: importlib_metadata>=0.20 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (4.42.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\aditya jain\\appdata\\roaming\\python\\python36\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_trf_distilbertbaseuncased_lg==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: sacremoses in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.0.38)\n",
      "Requirement already satisfied: boto3 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.11.9)\n",
      "Requirement already satisfied: sentencepiece in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.1.85)\n",
      "Requirement already satisfied: regex in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (2020.1.8)\n",
      "Requirement already satisfied: wcwidth in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from ftfy<6.0.0,>=5.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.1.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from importlib_metadata>=0.20->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.6.0)\n",
      "Requirement already satisfied: joblib in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.14.1)\n",
      "Requirement already satisfied: six in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.14.0)\n",
      "Requirement already satisfied: click in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (7.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\aditya jain\\appdata\\roaming\\python\\python36\\site-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.3.2)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (1.14.9)\n",
      "Requirement already satisfied: more-itertools in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from zipp>=0.5->importlib_metadata>=0.20->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (8.0.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\aditya jain\\appdata\\roaming\\python\\python36\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers>=0.5.0->en_trf_distilbertbaseuncased_lg==2.2.0) (0.15.2)\n",
      "Building wheels for collected packages: en-trf-distilbertbaseuncased-lg, spacy-transformers, torchcontrib, ftfy\n",
      "  Building wheel for en-trf-distilbertbaseuncased-lg (setup.py): started\n",
      "  Building wheel for en-trf-distilbertbaseuncased-lg (setup.py): finished with status 'done'\n",
      "  Created wheel for en-trf-distilbertbaseuncased-lg: filename=en_trf_distilbertbaseuncased_lg-2.2.0-py3-none-any.whl size=245033124 sha256=4d1b3deb504453890c20860faf476b0ecdb2fbd374c952326e2eafa2c418cec2\n",
      "  Stored in directory: C:\\Users\\ADITYA~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-qh33bkck\\wheels\\ac\\21\\e6\\6546be28e5ec7ec60cf46c2c90d3f818dc179d3421df8f6d2c\n",
      "  Building wheel for spacy-transformers (setup.py): started\n",
      "  Building wheel for spacy-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for spacy-transformers: filename=spacy_transformers-0.5.1-py2.py3-none-any.whl size=52838 sha256=1d0d4e8c8aa3f2cb7bcdb8eb74e8f2c85de21065f92e220a58c166ac5304b268\n",
      "  Stored in directory: C:\\Users\\ADITYA~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-qh33bkck\\wheels\\5b\\fc\\ec\\3f07ac701437c5b06685db7fc64d9a963d1e6c8fcff62922f3\n",
      "  Building wheel for torchcontrib (setup.py): started\n",
      "  Building wheel for torchcontrib (setup.py): finished with status 'done'\n",
      "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7536 sha256=9ab4f052fc9783ff2ade5b98f9393011e3c01345224ddce660147a18eec74fed\n",
      "  Stored in directory: C:\\Users\\ADITYA~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-qh33bkck\\wheels\\cc\\fc\\93\\b060f81a70c264ecc80a21158efc6034712bd6144f9fe53d02\n",
      "  Building wheel for ftfy (setup.py): started\n",
      "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
      "  Created wheel for ftfy: filename=ftfy-5.6-py3-none-any.whl size=44556 sha256=096bac99fa04b26a52753af456afe5c30c2b5340b653c920c20ac09e65805630\n",
      "  Stored in directory: C:\\Users\\ADITYA~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-qh33bkck\\wheels\\22\\e3\\08\\bc85bd99c87c453a4329d3a5f9af5bf1364af38ebd462353f0\n",
      "Successfully built en-trf-distilbertbaseuncased-lg spacy-transformers torchcontrib ftfy\n",
      "Installing collected packages: transformers, torchcontrib, ftfy, dataclasses, spacy-transformers, en-trf-distilbertbaseuncased-lg\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.3.0\n",
      "    Uninstalling transformers-2.3.0:\n",
      "      Successfully uninstalled transformers-2.3.0\n",
      "Successfully installed dataclasses-0.6 en-trf-distilbertbaseuncased-lg-2.2.0 ftfy-5.6 spacy-transformers-0.5.1 torchcontrib-0.0.2 transformers-2.0.0\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_trf_distilbertbaseuncased_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_trf_distilbertbaseuncased_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_trf_distilbertbaseuncased_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "document= nlp('settlement capabilities in india')\n",
    "showEnts(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-transformers in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (1.4.0)\n",
      "Requirement already satisfied: transformers<2.1.0,>=2.0.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (2.0.0)\n",
      "Requirement already satisfied: torchcontrib<0.1.0,>=0.0.2 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (0.0.2)\n",
      "Requirement already satisfied: ftfy<6.0.0,>=5.0.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (5.6)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (1.4.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.7 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (1.0.1)\n",
      "Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (0.6)\n",
      "Requirement already satisfied: spacy<2.3.0,>=2.2.1 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy-transformers) (2.2.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (0.1.85)\n",
      "Requirement already satisfied: sacremoses in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (0.0.38)\n",
      "Requirement already satisfied: tqdm in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (4.42.0)\n",
      "Requirement already satisfied: numpy in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (1.18.1)\n",
      "Requirement already satisfied: requests in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (2.22.0)\n",
      "Requirement already satisfied: boto3 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (1.11.9)\n",
      "Requirement already satisfied: regex in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from transformers<2.1.0,>=2.0.0->spacy-transformers) (2020.1.8)\n",
      "Requirement already satisfied: wcwidth in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from ftfy<6.0.0,>=5.0.0->spacy-transformers) (0.1.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy-transformers) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (2.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (45.1.0.post20200127)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from spacy<2.3.0,>=2.2.1->spacy-transformers) (0.6.0)\n",
      "Requirement already satisfied: click in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.14.1)\n",
      "Requirement already satisfied: six in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from sacremoses->transformers<2.1.0,>=2.0.0->spacy-transformers) (1.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from requests->transformers<2.1.0,>=2.0.0->spacy-transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\aditya jain\\appdata\\roaming\\python\\python36\\site-packages (from requests->transformers<2.1.0,>=2.0.0->spacy-transformers) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from requests->transformers<2.1.0,>=2.0.0->spacy-transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from requests->transformers<2.1.0,>=2.0.0->spacy-transformers) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\aditya jain\\appdata\\roaming\\python\\python36\\site-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (1.14.9)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.3.2)\n",
      "Requirement already satisfied: more-itertools in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->spacy-transformers) (8.0.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\aditya jain\\appdata\\roaming\\python\\python36\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\machinelearning\\anaconda3\\envs\\transformers-gpu\\lib\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers<2.1.0,>=2.0.0->spacy-transformers) (2.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
