{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "\n",
    "    This notebook is meant to understand outputs of DistilBert model in a visual manner. It is inspired by an article at \n",
    "\n",
    "<a href=\"http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">Jay Alammar</a>\n",
    "    \n",
    "<img src=\"http://jalammar.github.io/images/distilBERT/bert-distilbert-tutorial-sentence-embedding.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the DistilBertModel & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertModel\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Input data\n",
    "    - Tokenize each input string, add special token and pad to max length\n",
    "    - Create a tensor object for each tokenized string\n",
    "    \n",
    "<img src=\"http://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'i love machine learning'\n",
    "s2 = 'i hate sleeping'\n",
    "sentences = [s1,s2]\n",
    "tokens =[]\n",
    "\n",
    "for s in sentences:\n",
    "  tokenized = tokenizer.encode(s, add_special_tokens=True, pad_to_max_length=True)\n",
    "  tokens.append(tokenized)\n",
    "  \n",
    "s_tensor = torch.tensor(tokens)\n",
    "\n",
    "#attention_mask_tensor = torch.tensor([attention_mask])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model and extract last hidden states\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/distilBERT/bert-distilbert-input-tokenization.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  last_hidden_states = model(s_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding = np.array(last_hidden_states[0][:,0,:])\n",
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Next ?\n",
    "\n",
    "    Now that we have the embeddings we can use any classification algorithm to do the classification\n",
    "    \n",
    "<img src=\"http://jalammar.github.io/images/distilBERT/distilbert-bert-sentiment-classifier.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP - Ignore code below for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "tokenizer_1 = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_1 = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'i love machine learning'\n",
    "s2 = 'i hate sleeping'\n",
    "sentences = [s1,s2]\n",
    "tokens =[]\n",
    "\n",
    "for s in sentences:\n",
    "  tokenized = tokenizer_1.encode(s, add_special_tokens=True, pad_to_max_length=True)\n",
    "  tokens.append(tokenized)\n",
    "  \n",
    "s_tensor = torch.tensor(tokens)\n",
    "\n",
    "#attention_mask_tensor = torch.tensor([attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  last_hidden_states = model_1(s_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1441, -0.0378],\n",
       "        [ 0.1396, -0.0364]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
