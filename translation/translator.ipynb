{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    " device_name = os.environ['COLAB_TPU_ADDR']\n",
    " TPU_ADDRESS = 'grpc://' + device_name\n",
    " print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
    "except KeyError:\n",
    " print('TPU not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLES=20000\n",
    "MAX_WORDS=20000\n",
    "BATCH_SIZE=64\n",
    "EPOCHS=50\n",
    "OOV_TOKEN=0\n",
    "EMBEDDING_DIM = 50\n",
    "MAX_SEQ_LENGTH=100\n",
    "VALIDATION_SPLIT_RATIO= 0.2\n",
    "LSTM_UNITS=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples is 10000\n"
     ]
    }
   ],
   "source": [
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1\n",
    "\n",
    "t = 0\n",
    "for line in open('./data/deu.txt', encoding='utf-8'):\n",
    "    t+=1\n",
    "    if t>MAX_SAMPLES :\n",
    "        break\n",
    "        \n",
    "    input_txt, target_txt = line.rstrip().split ('\\t')\n",
    "    \n",
    "    target_txt_input = '<sos> '+target_txt\n",
    "    target_txt = target_txt +' <eos>'\n",
    "    \n",
    "    input_texts.append (input_txt)\n",
    "    target_texts_inputs.append(target_txt_input)\n",
    "    target_texts.append(target_txt)\n",
    "    \n",
    "print ('Num samples is %d'%(len(input_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max seq length of english sentences is 5\n",
      "Found 3131 unique english words\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS, oov_token=OOV_TOKEN, filters='')\n",
    "en_tokenizer.fit_on_texts(input_texts)\n",
    "en_word2Idx = en_tokenizer.word_index\n",
    "en_num_words = len(en_word2Idx)+1\n",
    "en_input_sequences = en_tokenizer.texts_to_sequences(input_texts)\n",
    "max_seq_len_en = min (MAX_SEQ_LENGTH, max(len(s) for s in en_input_sequences))\n",
    "padded_input_sequences = tf.keras.preprocessing.sequence.pad_sequences(en_input_sequences, padding='post', maxlen=max_seq_len_en)\n",
    "\n",
    "print ('Max seq length of english sentences is %d'%(max_seq_len_en))\n",
    "print ('Found %d unique english words'%(en_num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5042 unique german words\n",
      "Max seq length of german target sentences is 11\n",
      "Max seq length of german target input sentences is 11\n"
     ]
    }
   ],
   "source": [
    "de_tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS, oov_token=OOV_TOKEN, filters='')\n",
    "de_tokenizer.fit_on_texts(target_texts+target_texts_inputs)\n",
    "de_word2Idx = de_tokenizer.word_index\n",
    "\n",
    "de_num_words = len(de_word2Idx)+1\n",
    "print ('Found %d unique german words'%(de_num_words))\n",
    "\n",
    "de_target_inputs_sequences = de_tokenizer.texts_to_sequences(target_texts_inputs) # this is for decoder input\n",
    "de_target_sequences = de_tokenizer.texts_to_sequences(target_texts) # this is for decoder output\n",
    "\n",
    "max_seq_len_target_inputs = min (MAX_SEQ_LENGTH, max(len(s) for s in de_target_inputs_sequences))\n",
    "max_seq_len_target = min (MAX_SEQ_LENGTH, max(len(s) for s in de_target_sequences))\n",
    "\n",
    "print ('Max seq length of german target sentences is %d'%(max_seq_len_target))\n",
    "print ('Max seq length of german target input sentences is %d'%(max_seq_len_target_inputs))\n",
    "\n",
    "padded_target_input_sequences = tf.keras.preprocessing.sequence.pad_sequences(de_target_inputs_sequences, padding='post', maxlen=max_seq_len_target_inputs)\n",
    "padded_target_sequences = tf.keras.preprocessing.sequence.pad_sequences(de_target_sequences, padding='post', maxlen=max_seq_len_target)\n",
    "\n",
    "assert ('<sos>' in de_word2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11, 5042)\n"
     ]
    }
   ],
   "source": [
    "one_hot_targets = np.zeros((len(padded_target_sequences), max_seq_len_target, de_num_words),dtype='float32')\n",
    "print (one_hot_targets.shape)\n",
    "for i, seq in enumerate(padded_target_sequences):\n",
    "    for j, word in enumerate(seq):\n",
    "        if (word>0):\n",
    "            one_hot_targets[i,j,word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer = tf.keras.layers.Embedding(input_dim = en_num_words,\n",
    "                               output_dim = EMBEDDING_DIM,\n",
    "                               input_length=max_seq_len_en, \n",
    "                               trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0915 00:56:19.748454  8752 deprecation.py:506] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "##### build the encoder model #####\n",
    "encoder_input_ = tf.keras.layers.Input(shape=(max_seq_len_en))\n",
    "encoder_x = embed_layer(encoder_input_)\n",
    "encoder_lstm_layer_0 = tf.keras.layers.LSTM(units=LSTM_UNITS, return_sequences=True, return_state=True)\n",
    "encoder_x,h,c = encoder_lstm_layer_0(encoder_x)\n",
    "encoder_states = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0915 00:56:20.005554  8752 deprecation.py:506] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "##### build the decoder model #####\n",
    "decoder_input_ = tf.keras.layers.Input(shape=(max_seq_len_target_inputs))\n",
    "target_embed_layer = tf.keras.layers.Embedding(input_dim = de_num_words,\n",
    "                               output_dim = EMBEDDING_DIM,\n",
    "                               input_length=max_seq_len_target_inputs, \n",
    "                               trainable=True)\n",
    "decoder_x = target_embed_layer(decoder_input_)\n",
    "decoder_lstm_layer_0 = tf.keras.layers.LSTM(units=LSTM_UNITS, return_sequences=True, return_state=True)\n",
    "decoder_x,_,_ = decoder_lstm_layer_0(decoder_x, initial_state=encoder_states)\n",
    "decoder_dense = tf.keras.layers.Dense(de_num_words, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 11)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 5, 100)       313100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 11, 100)      504200      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 5, 10), (Non 4440        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 11, 10), (No 4440        embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 11, 5042)     55462       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 881,642\n",
      "Trainable params: 881,642\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##### build the encoder-decoder model #####\n",
    "model = tf.keras.models.Model([encoder_input_, decoder_input_], decoder_outputs)\n",
    "model.compile (optimizer=tf.keras.optimizers.Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(batch_size=1024):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset_ip = tf.data.Dataset.from_tensor_slices((padded_input_sequences, padded_target_input_sequences))\n",
    "    dataset_op = tf.data.Dataset.from_tensor_slices(one_hot_targets)\n",
    "    dataset = tf.data.Dataset.zip((dataset_ip, dataset_op))\n",
    "    \n",
    "    #dataset = tf.data.Dataset.from_tensor_slices(([padded_input_sequences,padded_target_input_sequences],one_hot_targets))\n",
    "# Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "# Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
    "    model,\n",
    "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = tpu_model.fit(\n",
    "    train_input_fn,\n",
    "    steps_per_epoch = 60,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0915 00:56:20.459819  8752 deprecation.py:323] From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 32s 4ms/sample - loss: 2.3637 - acc: 0.0696 - val_loss: 2.4465 - val_acc: 0.0909\n"
     ]
    }
   ],
   "source": [
    "history = model.fit ([padded_input_sequences,padded_target_input_sequences], one_hot_targets, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT_RATIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Training Metadata (Accuracy & Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "figure = plt.figure()\n",
    "\n",
    "ax1 = figure.add_subplot(211)\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(labels=['Training','Validation'])\n",
    "\n",
    "ax1 = figure.add_subplot(212)\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(labels=['Training','Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create Encoder Model for Inference ######\n",
    "encoder_model = tf.keras.models.Model(encoder_input_, encoder_states)\n",
    "\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(LSTM_UNITS,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(LSTM_UNITS,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = tf.keras.layers.Input(shape=(1,))\n",
    "decoder_inputs_single_x = target_embed_layer(decoder_inputs_single)\n",
    "decoder_ouput_single_x, h,c = decoder_lstm_layer_0(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [h, c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_ouput_single_x)\n",
    "\n",
    "decoder_model = tf.keras.models.Model(\n",
    "  [decoder_inputs_single] +decoder_states_inputs, \n",
    "  [decoder_outputs]+ decoder_states\n",
    ")\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in en_word2Idx.items()}\n",
    "idx2word_trans = {v:k for k, v in de_word2Idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    target_seq[0, 0] = de_word2Idx['<sos>']\n",
    "    eos = de_word2Idx['<eos>']\n",
    "    output_sentence = []\n",
    "    for _ in range (len(de_target_inputs_sequences)):\n",
    "        output_tokens, h,c = decoder_model.predict([target_seq] +encoder_states_value)\n",
    "        \n",
    "        # Get next word\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "        if idx == eos:\n",
    "            print ('stopping...')\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "        if idx >0 :\n",
    "            word = idx2word_trans[idx]\n",
    "            output_sentence.append(word)\n",
    "        \n",
    "        target_seq[0, 0] = idx\n",
    "            \n",
    "        encoder_states_value = [h,c]\n",
    "    \n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input - Go away!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-77652830c63a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpadded_input_sequences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Input -'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Translated -'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-778b1dff20fb>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mde_target_inputs_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutput_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_states_value\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Get next word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;31m# generate symbolic tensors).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[1;32m-> 1060\u001b[1;33m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2651\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    332\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     data = [\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     ]\n\u001b[0;32m    336\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    332\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     data = [\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     ]\n\u001b[0;32m    336\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x, expected_shape)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m   if (x.shape is not None and len(x.shape) == 1 and\n\u001b[0m\u001b[0;32m    266\u001b[0m       (expected_shape is None or len(expected_shape) != 1)):\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_texts))\n",
    "input_seq = padded_input_sequences[i:i+1]\n",
    "print ('Input -', input_texts[i])\n",
    "translated = decode_sequence (input_seq)\n",
    "print ('Translated -', translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
